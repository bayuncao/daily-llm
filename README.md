# daily-llm

[å†™åœ¨å¼€å§‹ä¹‹å‰çš„è¯](./PREFACE.md)

## CH.0 - ä»å…´è¶£å‡ºå‘è€Œä¸æ˜¯ä¸ºäº†å·¥ä½œ

> æˆ‘å¼ºçƒˆå»ºè®®æ¯å¤©éƒ½æ¥ç¿»çœ‹è¿™ä¸€ç« èŠ‚ä¸­çš„å†…å®¹ï¼Œå®ƒæ˜¯æˆ‘ä¸æ–­åœ¨å…¨ç½‘æœé›†çš„ç§‘æ™®å‘å†…å®¹ï¼ˆå›¾æ–‡ã€è§†é¢‘ã€è®²åº§ç­‰ï¼‰ï¼Œä½ å¯ä»¥åˆ©ç”¨ä¸€åˆ‡ç¢ç‰‡åŒ–çš„äº‹ä»¶æ¥æ ¹æ®ä½ çš„å…´è¶£æˆ–è€…å¹²è„†éšæœºè§‚çœ‹ã€‚
>
> CH.0ä¸­çš„å†…å®¹å¤§å¤šéƒ½æ²¡æœ‰å…³è”ã€‚æˆ‘å¸Œæœ›åœ¨è¿™ä¸ªç« èŠ‚ä¸­ä½ å¯ä»¥å…ˆç§¯ç´¯å¤§æ¨¡å‹ç›¸å…³çš„èƒŒæ™¯ã€å†å²åŠè¶£å‘³å¸¸è¯†ï¼Œå¸Œæœ›ä½ èƒ½å¤ŸGetåˆ°æˆ‘æƒ³å°½ä¸€åˆ‡åŠæ³•å‡ä½ä½ çš„å­¦ä¹ ç„¦è™‘çš„åˆå¿ƒğŸ«¡ã€‚


1. [å›¾çµè®²åº§ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æœªæ¥](https://youtu.be/2kSl0xkq2lM)

   è¿ˆå…‹å°”Â·ä¼å°”å¾·é‡Œå¥‡æ•™æˆå…³äºç”Ÿæˆå¼AIæœªæ¥å¯èƒ½æ€§åŠå¯¹ç¤¾ä¼šå½±å“çš„è®¨è®ºï¼Œè¿™æ˜¯â€œAIå¦‚ä½•æ‰“ç ´äº’è”ç½‘â€å›¾çµè®²åº§ç³»åˆ—çš„ä¸€éƒ¨åˆ†ã€‚

2. [ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç®€è€Œè¨€ä¹‹â€”â€”å¦‚ä½•åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ç”Ÿå­˜å’Œå‘å±•](https://youtu.be/2IK3DFHRFfw)


## CH.1 - åŸºç¡€ä¸ç‰¢åœ°åŠ¨å±±æ‘‡

> å½“ä½ åœ¨CH.0è§‚çœ‹äº†10ä¸ªä»¥ä¸Šçš„è§†é¢‘ä¹‹åï¼Œæˆ‘ç›¸ä¿¡ä½ å·²ç»å¯¹ç”Ÿæˆå¼å¤§è¯­è¨€æ¨¡å‹æœ‰äº†ä¸€ä¸ªå¿«é€Ÿä¾§å†™çš„è®¤çŸ¥ã€‚
>
> æ¥ä¸‹æ¥æˆ‘å¸Œæœ›ä½ ç”¨å‡ å¤©çš„æ—¶é—´ï¼Œé€šç¯‡é˜…è¯»ä¸€ä¸‹CH.1ä¸­çš„å†…å®¹ã€‚å®ƒä»¬æ˜¯å¤§æ¨¡å‹é¢†åŸŸçš„ç»å…¸è®ºæ–‡ï¼Œæ¶‰åŠäº†å¤šä¸ªæ–¹é¢ï¼ŒåŒ…æ‹¬æ¨¡å‹æ¶æ„ã€è®­ç»ƒæ–¹æ³•ã€ä¼˜åŒ–ç®—æ³•ç­‰ã€‚è¿™äº›è®ºæ–‡ä¸ºå¤§æ¨¡å‹çš„å‘å±•å¥ å®šäº†åŸºç¡€æˆ–å¼•é¢†äº†é‡è¦çš„æŠ€æœ¯æ–¹å‘ã€‚
>
> å½“ç„¶ï¼Œé˜…è¯»è®ºæ–‡çš„è¿‡ç¨‹ç¡®å®æ˜¯æ¯ç‡¥ä¹å‘³ä¸”ä»¤äººæŠ“ç‹‚ã€‚æˆ‘ä¹Ÿå¹¶ä¸å¯¹ä½ åšå‡ºå­¦æœ¯ç•Œçš„è¦æ±‚ï¼Œä½†æ˜¯èµ·ç è¦é€šè¯»ä¸€éã€‚ç›¸ä¿¡æˆ‘ï¼Œè¿™ä¼šåœ¨åé¢çš„å®è·µä¸­å‘æŒ¥å‡ºå·¨å¤§çš„ä½œç”¨ã€‚


1. ["Attention is All You Need" by Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762)

   ä»‹ç»äº†Transformeræ¨¡å‹ï¼Œå®ƒæ˜¯ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹å¦‚GPTç³»åˆ—å’ŒBERTç³»åˆ—çš„åŸºç¡€ã€‚Transformeræ¶æ„é€šè¿‡è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰æœºåˆ¶æœ‰æ•ˆåœ°å¤„ç†åºåˆ—æ•°æ®ï¼Œæ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨ã€‚

2. ["BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" by Devlin et al. (2018)](https://arxiv.org/abs/1810.04805)
   
   æå‡ºäº†BERTæ¨¡å‹ï¼Œå®ƒé‡‡ç”¨åŒå‘Transformeré¢„è®­ç»ƒæ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†å¤šé¡¹NLPä»»åŠ¡çš„æ€§èƒ½ã€‚BERTçš„å‡ºç°æ ‡å¿—ç€é¢„è®­ç»ƒ+å¾®è°ƒçš„æ–¹æ³•æˆä¸ºNLPé¢†åŸŸçš„æ ‡å‡†èŒƒå¼ã€‚

3. ["Improving language understanding with unsupervised learning"](https://openai.com/research/language-unsupervised)
   
   è®¨è®ºäº†ä½¿ç”¨transformerså’Œæ— ç›‘ç£é¢„è®­ç»ƒç›¸ç»“åˆçš„æ–¹æ³•ï¼Œä»¥åŠè¿™ç§æ–¹æ³•åœ¨å¤šæ ·åŒ–è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚å®ƒå¼ºè°ƒäº†è¿™ç§å¯æ‰©å±•ã€ä»»åŠ¡ä¸å¯çŸ¥çš„ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼Œå¹¶æåˆ°ç³»ç»Ÿä¹Ÿå°†è¢«å…¬å¼€ã€‚è¿™ç§ç»“åˆä½¿ç”¨æœ‰ç›‘ç£å­¦ä¹ æ–¹æ³•å’Œæ— ç›‘ç£é¢„è®­ç»ƒçš„æ–¹æ³•éå¸¸æœ‰æ•ˆï¼Œ

4. "Language Models are Unsupervised Multitask Learners" by Radford et al. (OpenAI, 2019)
    
    ç»§GPTä¹‹åä»‹ç»äº†GPT-2æ¨¡å‹ï¼Œå®ƒé€šè¿‡æ›´å¤§çš„æ¨¡å‹å’Œæ›´å¤šçš„æ•°æ®ï¼Œå±•ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨æ²¡æœ‰æ˜ç¡®ä»»åŠ¡æŒ‡å¯¼çš„æƒ…å†µä¸‹ï¼Œä»ç„¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬å’Œåœ¨å¤šç§NLPä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚

5. "Scaling Laws for Neural Language Models" by Kaplan et al. (OpenAI, 2020)
   
   é€šè¿‡å®éªŒç ”ç©¶äº†æ¨¡å‹è§„æ¨¡ã€æ•°æ®é›†å¤§å°å’Œè®¡ç®—é¢„ç®—å¦‚ä½•å…±åŒå½±å“è¯­è¨€æ¨¡å‹æ€§èƒ½çš„è§„å¾‹ï¼Œä¸ºè®¾è®¡å’Œè®­ç»ƒå¤§å‹æ¨¡å‹æä¾›äº†ç†è®ºæŒ‡å¯¼ã€‚

6. "Improving Language Understanding by Generative Pre-Training" by Radford et al. (OpenAI, pre-GPT-3)

    GPT-1çš„è®ºæ–‡æ ‡å¿—ç€ç”Ÿæˆå¼é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å¼€å§‹ã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œç„¶ååœ¨å…·ä½“ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œæ˜¾è‘—æå‡äº†å¤šé¡¹è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡çš„æ€§èƒ½ã€‚

7. "GPT-3: Language Models are Few-Shot Learners" by Brown et al. (OpenAI, 2020)

    å±•ç¤ºäº†é€šè¿‡å¤§è§„æ¨¡æ‰©å±•æ¨¡å‹è§„æ¨¡ï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥è¿›è¡Œå°‘æ ·æœ¬å­¦ä¹ ï¼Œå³åœ¨å‡ ä¹æ²¡æœ‰ä»»åŠ¡ç‰¹å®šæ•°æ®çš„æƒ…å†µä¸‹é€šè¿‡ä»»åŠ¡æè¿°æ¥å®Œæˆä»»åŠ¡ã€‚è¿™æ ‡å¿—ç€è¯­è¨€æ¨¡å‹å‘æ›´åŠ é€šç”¨çš„äººå·¥æ™ºèƒ½æ–¹å‘è¿ˆè¿›äº†ä¸€æ­¥ã€‚

8. "T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer" by Raffel et al. (2019)

    æå‡ºäº†T5æ¨¡å‹ï¼Œå¼ºè°ƒå°†æ‰€æœ‰æ–‡æœ¬å¤„ç†ä»»åŠ¡ç»Ÿä¸€ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬çš„æ ¼å¼ï¼Œæ¢ç´¢äº†è¿ç§»å­¦ä¹ çš„æé™ã€‚è¿™ç§æ–¹æ³•ç®€åŒ–äº†ä¸åŒNLPä»»åŠ¡ä¹‹é—´çš„è½¬æ¢ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å®¹æ˜“åœ°åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå…±äº«çŸ¥è¯†ã€‚

9.  "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations" by Lan et al. (2019)

    æå‡ºäº†ALBERTæ¨¡å‹ï¼Œé€šè¿‡å‚æ•°å…±äº«å’Œé™ä½æ¨¡å‹å¤§å°çš„ç­–ç•¥ï¼Œæé«˜äº†æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡å’Œæ€§èƒ½ã€‚ALBERTå¯¹äºç†è§£å¦‚ä½•åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶å‡å°‘èµ„æºæ¶ˆè€—æä¾›äº†é‡è¦çš„è§è§£ã€‚

10. "XLNet: Generalized Autoregressive Pretraining for Language Understanding" by Yang et al. (2019)

    æå‡ºäº†XLNetï¼Œé€šè¿‡ç»“åˆè‡ªå›å½’è¯­è¨€æ¨¡å‹å’ŒBERTçš„ä¼˜ç‚¹ï¼Œæ”¹è¿›äº†æ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£èƒ½åŠ›ã€‚XLNetåœ¨å¤šé¡¹NLPä»»åŠ¡ä¸Šè®¾ç½®äº†æ–°çš„æ€§èƒ½åŸºå‡†ï¼Œå±•ç¤ºäº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥æ¼”è¿›ã€‚


---
## CH.2 - çª¥ä¸€æ–‘è€ŒçŸ¥å…¨è±¹

> è¿™ä¸€ç« èŠ‚ä¸­çš„å†…å®¹é€Ÿé€šï¼Œè§†é¢‘å¯ä»¥å€é€Ÿã€æ–‡ç« å¯ä»¥é€Ÿè§ˆã€‚åŠ›æ±‚åœ¨æœ€çŸ­çš„æ—¶é—´å†…å°†å…¨éƒ¨æ¦‚å¿µå’Œæœ¯è¯­çŸ¥æ™“ï¼Œè¿™äº›å†…å®¹æœ€å¥½åœ¨ä½ çš„ç¬”è®°ä¸­è®°å½•æ¯ä¸€ä¸ªæ–°é²œäº‹ç‰©å‡ºç°çš„æ—¶é—´ç‚¹ï¼Œæœªæ¥å½“ä½ éœ€è¦æ·±å…¥ç ”ç©¶çš„æ—¶å€™å¯ä»¥ç›´æ¥Jumpè¿›æ¥å†é‡æ–°ç²¾è¯»ã€‚

1. [50 Days to AI/ML: from Zero to Hero (for non-CS background)](https://medium.com/@sibtainwahab/50-days-to-ai-ml-from-zero-to-hero-for-non-cs-background-6f256a7d03b7)
   
    æä¾›äº†ä¸€ä¸ª50å¤©è‡ªå­¦æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„è·¯çº¿å›¾ï¼Œæ—¨åœ¨å¸®åŠ©å¯¹è¿™ä¸€é¢†åŸŸæ„Ÿå…´è¶£ä½†æ²¡æœ‰æŠ€æœ¯èƒŒæ™¯çš„äººè¿…é€Ÿå…¥é—¨ã€‚è·¯çº¿å›¾ä»åŸºç¡€çš„æ•°å­¦çŸ¥è¯†å¼€å§‹ï¼Œç„¶åé€æ­¥æ·±å…¥åˆ°Pythonç¼–ç¨‹ã€ä½¿ç”¨Numpyã€Pandasã€Matplotlibç­‰åº“ï¼Œå†åˆ°æ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µï¼Œæœ€åé€šè¿‡å®è·µé¡¹ç›®æ¥å·©å›ºæ‰€å­¦çŸ¥è¯†ã€‚æ–‡ç« å¼ºè°ƒäº†å­¦ä¹ è¿‡ç¨‹ä¸­å¯¹é—®é¢˜è§£å†³èƒ½åŠ›ã€å­¦ä¹ æ„æ„¿å’Œè·å¾—ç›¸å…³è¯ä¹¦çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºä¸éœ€è¦æŠ€æœ¯èƒŒæ™¯æˆ–è®¡ç®—æœºç§‘å­¦/äººå·¥æ™ºèƒ½å­¦ä½å°±å¯ä»¥å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ ã€‚æ•´ä¸ªè·¯çº¿å›¾æ˜¯ä½œè€…æ ¹æ®ä¸ªäººç»éªŒæ•´ç†çš„ï¼Œç›®çš„æ˜¯è®©è¯»è€…èƒ½å¤Ÿåœ¨çŸ­æ—¶é—´å†…æœ‰æ•ˆå­¦ä¹ å¹¶è¿›å…¥æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„é¢†åŸŸã€‚

---
## CH.99 - æ–¹å‘ä¸å¯¹åŠªåŠ›ç™½è´¹

> æˆ‘æ¨èçš„å…¨ç½‘å¯å…³æ³¨çš„Upä¸»ï¼Œæ’åä¸åˆ†å…ˆåã€‚ä½†æ˜¯å½“ä½ çœ‹åˆ°æŸä¸ªUpå¸¦æœ‰ğŸ”­æ ‡è®°ï¼Œé‚£ä¹ˆå»ºè®®ä½ å°†ä»–/å¥¹çš„æ‰€æœ‰è§†é¢‘å…¨éƒ¨çœ‹å®Œã€‚

### çŸ¥ä¹

### YouTube

### BiliBili

### Medium

---

## CH.99 - å·¥æ¬²å–„å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨


---

## CH.100 - æŒ‰å›¾ç´¢éª¥

> è¿™æ˜¯æœé›†åˆ°çš„å…·æœ‰å±€éƒ¨å®è§‚çš„å›¾ç‰‡ã€‚æ¯å¼ å›¾ç‰‡ä¼šæ³¨æ˜å‡ºå¤„ã€‚

![alt generative-AI-in-a-nutshell](picture/generative-AI-in-a-nutshell.png "generative-AI-in-a-nutshell")

<p align="center"><a href="https://www.youtube.com/watch?v=2IK3DFHRFfw">å›¾ç‰‡å‡ºå¤„</a></p>

---


### CONTRIBUTING
å¦‚æœæœ‰æ›´å¥½çš„èµ„æºæˆ–è¯¾ç¨‹ï¼Œæ¬¢è¿æäº¤Issuesã€‚
å¦‚æœ‰å†…å®¹ä¾µæƒè¯·è”ç³»æˆ‘ï¼ˆODUzMzU5NkBnbWFpbC5jb20=ï¼‰ã€‚
