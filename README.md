# daily-llm

[写在开始之前的话](./PREFACE.md)

## CH.0 - 从兴趣出发而不是为了工作

> 我强烈建议每天都来翻看这一章节中的内容，它是我不断在全网搜集的科普向内容（图文、视频、讲座等），你可以利用一切碎片化的事件来根据你的兴趣或者干脆随机观看。
>
> CH.0中的内容大多都没有关联。我希望在这个章节中你可以先积累大模型相关的背景、历史及趣味常识，希望你能够Get到我想尽一切办法减低你的学习焦虑的初心🫡。

- [📔 CH.0 -> 正文内容](./chapter/CH.0.md)
- [🕘 CH.0 -> 更新记录](./changelog/CH.0.changelog.md)


## CH.1 - 基础不牢地动山摇

> 当你在CH.0观看了10个以上的视频之后，我相信你已经对生成式大语言模型有了一个快速侧写的认知。
>
> 接下来我希望你用几天的时间，通篇阅读一下CH.1中的内容。它们是大模型领域的经典论文，涉及了多个方面，包括模型架构、训练方法、优化算法等。这些论文为大模型的发展奠定了基础或引领了重要的技术方向。
>
> 当然，阅读论文的过程确实是枯燥乏味且令人抓狂。我也并不对你做出学术界的要求，但是起码要通读一遍。相信我，这会在后面的实践中发挥出巨大的作用。

- [📔 CH.1 -> 正文内容](./chapter/CH.1.md)
- [🕘 CH.1 -> 更新记录](./changelog/CH.1.changelog.md)

## CH.99 - 方向不对努力白费

> 我推荐的全网可关注的Up主，排名不分先后。但是当你看到某个Up带有🔭标记，那么建议你将他/她的所有视频全部看完。


- [📔 CH.99 -> 正文内容](./chapter/CH.99.md)
- [🕘 CH.99 -> 更新记录](./changelog/CH.99.changelog.md)